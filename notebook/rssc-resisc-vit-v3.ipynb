{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11996609,"sourceType":"datasetVersion","datasetId":7546158}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls ../input/stratified-nwpu-resisc45-500-trainval7015/STRATIFIED_NWPU-RESISC45-500-TRAINVAL7015","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:51:57.163768Z","iopub.execute_input":"2025-06-13T03:51:57.164005Z","iopub.status.idle":"2025-06-13T03:51:57.294764Z","shell.execute_reply.started":"2025-06-13T03:51:57.163982Z","shell.execute_reply":"2025-06-13T03:51:57.293859Z"}},"outputs":[{"name":"stdout","text":"train  val\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:51:57.297278Z","iopub.execute_input":"2025-06-13T03:51:57.297508Z","iopub.status.idle":"2025-06-13T03:51:57.463567Z","shell.execute_reply.started":"2025-06-13T03:51:57.297486Z","shell.execute_reply":"2025-06-13T03:51:57.462728Z"}},"outputs":[{"name":"stdout","text":"Fri Jun 13 03:51:57 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   31C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\nimport joblib\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:51:57.465060Z","iopub.execute_input":"2025-06-13T03:51:57.465394Z","iopub.status.idle":"2025-06-13T03:52:11.133069Z","shell.execute_reply.started":"2025-06-13T03:51:57.465348Z","shell.execute_reply":"2025-06-13T03:52:11.132526Z"}},"outputs":[{"name":"stderr","text":"2025-06-13 03:51:58.860496: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749786719.047983      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749786719.102147      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tf.config.list_logical_devices()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:11.133713Z","iopub.execute_input":"2025-06-13T03:52:11.134098Z","iopub.status.idle":"2025-06-13T03:52:12.193283Z","shell.execute_reply.started":"2025-06-13T03:52:11.134081Z","shell.execute_reply":"2025-06-13T03:52:12.192304Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1749786732.185786      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n LogicalDevice(name='/device:GPU:0', device_type='GPU')]"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"path_ds = \"../input/stratified-nwpu-resisc45-500-trainval7015/STRATIFIED_NWPU-RESISC45-500-TRAINVAL7015\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:12.194740Z","iopub.execute_input":"2025-06-13T03:52:12.195715Z","iopub.status.idle":"2025-06-13T03:52:12.224424Z","shell.execute_reply.started":"2025-06-13T03:52:12.195686Z","shell.execute_reply":"2025-06-13T03:52:12.223536Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import datasets\n \ndef create_image_folder_dataset(root_path):\n  \"\"\"creates `Dataset` from image folder structure\"\"\"\n \n  # get class names by folders names\n  _CLASS_NAMES= os.listdir(root_path)\n  # defines `datasets` features`\n  features=datasets.Features({\n                      \"img\": datasets.Image(),\n                      \"label\": datasets.features.ClassLabel(names=_CLASS_NAMES),\n                  })\n  # temp list holding datapoints for creation\n  img_data_files=[]\n  label_data_files=[]\n  # load images into list for creation\n  for img_class in os.listdir(root_path):\n    for img in os.listdir(os.path.join(root_path,img_class)):\n      path_=os.path.join(root_path,img_class,img)\n      img_data_files.append(path_)\n      label_data_files.append(img_class)\n  # create dataset\n  ds = datasets.Dataset.from_dict({\"img\":img_data_files,\"label\":label_data_files},features=features)\n  return ds\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:12.225318Z","iopub.execute_input":"2025-06-13T03:52:12.225596Z","iopub.status.idle":"2025-06-13T03:52:13.353849Z","shell.execute_reply.started":"2025-06-13T03:52:12.225576Z","shell.execute_reply":"2025-06-13T03:52:13.353310Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"train_ds = create_image_folder_dataset(f\"{path_ds}/train\")\ntrain_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:13.355967Z","iopub.execute_input":"2025-06-13T03:52:13.356436Z","iopub.status.idle":"2025-06-13T03:52:14.031917Z","shell.execute_reply.started":"2025-06-13T03:52:13.356416Z","shell.execute_reply":"2025-06-13T03:52:14.031146Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['img', 'label'],\n    num_rows: 15750\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"val_ds = create_image_folder_dataset(f\"{path_ds}/val\")\nval_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:14.032630Z","iopub.execute_input":"2025-06-13T03:52:14.032830Z","iopub.status.idle":"2025-06-13T03:52:14.399087Z","shell.execute_reply.started":"2025-06-13T03:52:14.032814Z","shell.execute_reply":"2025-06-13T03:52:14.398421Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['img', 'label'],\n    num_rows: 3375\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"classes = train_ds.features[\"label\"].names\nclasses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:14.399846Z","iopub.execute_input":"2025-06-13T03:52:14.400075Z","iopub.status.idle":"2025-06-13T03:52:14.405128Z","shell.execute_reply.started":"2025-06-13T03:52:14.400050Z","shell.execute_reply":"2025-06-13T03:52:14.404479Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['airplane',\n 'cloud',\n 'mountain',\n 'medium_residential',\n 'thermal_power_station',\n 'terrace',\n 'commercial_area',\n 'dense_residential',\n 'baseball_diamond',\n 'mobile_home_park',\n 'ship',\n 'airport',\n 'river',\n 'golf_course',\n 'roundabout',\n 'church',\n 'circular_farmland',\n 'overpass',\n 'railway',\n 'wetland',\n 'lake',\n 'parking_lot',\n 'intersection',\n 'tennis_court',\n 'runway',\n 'industrial_area',\n 'chaparral',\n 'bridge',\n 'sparse_residential',\n 'freeway',\n 'sea_ice',\n 'beach',\n 'palace',\n 'snowberg',\n 'meadow',\n 'ground_track_field',\n 'harbor',\n 'rectangular_farmland',\n 'island',\n 'basketball_court',\n 'desert',\n 'stadium',\n 'forest',\n 'storage_tank',\n 'railway_station']"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"from transformers import ViTFeatureExtractor\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n \nmodel_id = \"google/vit-base-patch16-224\"\n\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_id)\n\n# basic processing (only resizing)\ndef process(examples):\n    examples.update(feature_extractor(examples['img'], ))\n    return examples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:14.405904Z","iopub.execute_input":"2025-06-13T03:52:14.406661Z","iopub.status.idle":"2025-06-13T03:52:22.638453Z","shell.execute_reply.started":"2025-06-13T03:52:14.406635Z","shell.execute_reply":"2025-06-13T03:52:22.637602Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcda401872f842ba9b2cfb8fca20f708"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train_ds = train_ds.rename_column(\"label\", \"labels\")\nval_ds = val_ds.rename_column(\"label\", \"labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:22.639348Z","iopub.execute_input":"2025-06-13T03:52:22.639831Z","iopub.status.idle":"2025-06-13T03:52:22.648075Z","shell.execute_reply.started":"2025-06-13T03:52:22.639812Z","shell.execute_reply":"2025-06-13T03:52:22.647209Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_ds_preprocessed = train_ds.map(process, batched=True)\ntrain_ds_preprocessed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:52:22.649236Z","iopub.execute_input":"2025-06-13T03:52:22.649914Z","iopub.status.idle":"2025-06-13T03:55:16.562023Z","shell.execute_reply.started":"2025-06-13T03:52:22.649889Z","shell.execute_reply":"2025-06-13T03:55:16.561386Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c4f2531797b427cabe9b6dbfa643009"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['img', 'labels', 'pixel_values'],\n    num_rows: 15750\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"val_ds_preprocessed = val_ds.map(process, batched=True) \nval_ds_preprocessed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:55:16.562915Z","iopub.execute_input":"2025-06-13T03:55:16.563419Z","iopub.status.idle":"2025-06-13T03:55:50.616206Z","shell.execute_reply.started":"2025-06-13T03:55:16.563392Z","shell.execute_reply":"2025-06-13T03:55:50.615646Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3375 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96999dbf48c400f96e79d3501715c4c"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['img', 'labels', 'pixel_values'],\n    num_rows: 3375\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Convert DS to TF Datasets","metadata":{}},{"cell_type":"code","source":"id2label = {str(i): label for i, label in enumerate(classes)}\nlabel2id = {v: k for k, v in id2label.items()}\n \nnum_train_epochs = 15\nbatch_size = 10\nlearning_rate = 1e-5\nweight_decay_rate = 1e-2\nnum_warmup_steps = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:55:50.616896Z","iopub.execute_input":"2025-06-13T03:55:50.617166Z","iopub.status.idle":"2025-06-13T03:55:50.621484Z","shell.execute_reply.started":"2025-06-13T03:55:50.617143Z","shell.execute_reply":"2025-06-13T03:55:50.620804Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from transformers import DefaultDataCollator\n \n# Data collator that will dynamically pad the inputs received, as well as the labels.\ndata_collator = DefaultDataCollator(return_tensors=\"tf\")\n \n# converting our train dataset to tf.data.Dataset\ntrain_data_no_augmentation = train_ds_preprocessed.to_tf_dataset(\n   columns=[\"pixel_values\"],\n   label_cols=[\"labels\"],\n   shuffle=True,\n   batch_size=batch_size,\n   collate_fn=data_collator)\n\n \n# converting our val dataset to tf.data.Dataset\nval_data = val_ds_preprocessed.to_tf_dataset(\n   columns=[\"pixel_values\"],\n   label_cols=[\"labels\"],\n   shuffle=True,\n   batch_size=batch_size,\n   collate_fn=data_collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:55:50.622636Z","iopub.execute_input":"2025-06-13T03:55:50.622902Z","iopub.status.idle":"2025-06-13T03:55:52.614014Z","shell.execute_reply.started":"2025-06-13T03:55:50.622880Z","shell.execute_reply":"2025-06-13T03:55:52.613487Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\nOld behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \nNew behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Apply Data Prefetch","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\ntrain_data_no_augmentation = train_data_no_augmentation.prefetch(buffer_size=AUTOTUNE)\nval_data = val_data.prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:55:52.781572Z","iopub.execute_input":"2025-06-13T03:55:52.781841Z","iopub.status.idle":"2025-06-13T03:55:52.788951Z","shell.execute_reply.started":"2025-06-13T03:55:52.781814Z","shell.execute_reply":"2025-06-13T03:55:52.788398Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"from transformers import TFViTForImageClassification, create_optimizer\nimport tensorflow as tf\n \n# create optimizer wight weigh decay\nnum_train_steps = len(train_data_with_augmentation) * num_train_epochs\noptimizer, lr_schedule = create_optimizer(\n    init_lr=learning_rate,\n    num_train_steps=num_train_steps,\n    weight_decay_rate=weight_decay_rate,\n    num_warmup_steps=num_warmup_steps,\n)\n\ndef vit():\n    # load pre-trained ViT model\n    model = TFViTForImageClassification.from_pretrained(\n        model_id,\n        num_labels=len(classes),\n        id2label=id2label,\n        label2id=label2id,\n        ignore_mismatched_sizes=True\n    ) \n     \n    # compile model\n    model.compile(\n        optimizer=optimizer,\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"]\n    )\n    \n    model.summary()\n    print(f\"\\n##### Optimizer Func Information\\n{model.optimizer.get_config()}\")\n    print(f\"\\n##### Loss Func Information\\n{model.loss.get_config()}\")\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:55:52.789663Z","iopub.execute_input":"2025-06-13T03:55:52.789886Z","iopub.status.idle":"2025-06-13T03:55:55.824831Z","shell.execute_reply.started":"2025-06-13T03:55:52.789863Z","shell.execute_reply":"2025-06-13T03:55:55.824288Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## 15 Epochs No Augmentation","metadata":{}},{"cell_type":"code","source":"base_vit_p16 = vit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:55:55.825859Z","iopub.execute_input":"2025-06-13T03:55:55.826102Z","iopub.status.idle":"2025-06-13T03:56:00.247551Z","shell.execute_reply.started":"2025-06-13T03:55:55.826080Z","shell.execute_reply":"2025-06-13T03:56:00.246997Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8d0acd25f3a4927ba629b6647fdbcd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2f8c772b8b44b328dcca709f63ef2f4"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTForImageClassification: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing TFViTForImageClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFViTForImageClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFViTForImageClassification were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\nSome weights of TFViTForImageClassification were not initialized from the model checkpoint are newly initialized because the shapes did not match:\n- classifier.weight: found shape (1000, 768) in the checkpoint and (768, 45) in the model instantiated\n- classifier.bias: found shape (1000,) in the checkpoint and (45,) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tf_vi_t_for_image_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vit (TFViTMainLayer)        multiple                  85798656  \n                                                                 \n classifier (Dense)          multiple                  34605     \n                                                                 \n=================================================================\nTotal params: 85833261 (327.43 MB)\nTrainable params: 85833261 (327.43 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n##### Optimizer Func Information\n{'name': 'AdamWeightDecay', 'learning_rate': {'module': 'keras.optimizers.schedules', 'class_name': 'PolynomialDecay', 'config': {'initial_learning_rate': 1e-05, 'decay_steps': 23625, 'end_learning_rate': 0.0, 'power': 1.0, 'cycle': False, 'name': None}, 'registered_name': None}, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-08, 'amsgrad': False, 'weight_decay_rate': 0.01}\n\n##### Loss Func Information\n{'name': 'sparse_categorical_crossentropy', 'reduction': 'sum_over_batch_size', 'from_logits': True, 'ignore_class': None}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"%%time\n\nhistory_base_vit_p16 = base_vit_p16.fit(\n    train_data_no_augmentation,\n    validation_data=val_data,\n    epochs=num_train_epochs,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T03:56:00.248237Z","iopub.execute_input":"2025-06-13T03:56:00.248443Z","iopub.status.idle":"2025-06-13T06:07:03.259261Z","shell.execute_reply.started":"2025-06-13T03:56:00.248427Z","shell.execute_reply":"2025-06-13T06:07:03.258620Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749786983.723728      96 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"1575/1575 [==============================] - 532s 322ms/step - loss: 1.4330 - accuracy: 0.7319 - val_loss: 0.4453 - val_accuracy: 0.9153\nEpoch 2/15\n1575/1575 [==============================] - 520s 330ms/step - loss: 0.2662 - accuracy: 0.9479 - val_loss: 0.2575 - val_accuracy: 0.9336\nEpoch 3/15\n1575/1575 [==============================] - 500s 318ms/step - loss: 0.0999 - accuracy: 0.9834 - val_loss: 0.1961 - val_accuracy: 0.9416\nEpoch 4/15\n1575/1575 [==============================] - 501s 318ms/step - loss: 0.0375 - accuracy: 0.9963 - val_loss: 0.1711 - val_accuracy: 0.9520\nEpoch 5/15\n1575/1575 [==============================] - 523s 332ms/step - loss: 0.0144 - accuracy: 0.9996 - val_loss: 0.1657 - val_accuracy: 0.9505\nEpoch 6/15\n1575/1575 [==============================] - 560s 356ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9532\nEpoch 7/15\n1575/1575 [==============================] - 541s 343ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9556\nEpoch 8/15\n1575/1575 [==============================] - 569s 361ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9561\nEpoch 9/15\n1575/1575 [==============================] - 577s 366ms/step - loss: 7.7275e-04 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9553\nEpoch 10/15\n1575/1575 [==============================] - 499s 316ms/step - loss: 4.2106e-04 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9553\nEpoch 11/15\n1575/1575 [==============================] - 503s 319ms/step - loss: 2.3775e-04 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9550\nEpoch 12/15\n1575/1575 [==============================] - 511s 324ms/step - loss: 1.4080e-04 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9547\nEpoch 13/15\n1575/1575 [==============================] - 517s 328ms/step - loss: 8.8316e-05 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9544\nEpoch 14/15\n1575/1575 [==============================] - 503s 320ms/step - loss: 6.0692e-05 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9553\nEpoch 15/15\n1575/1575 [==============================] - 506s 321ms/step - loss: 4.7888e-05 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9550\nCPU times: user 2h 28min 47s, sys: 8min 47s, total: 2h 37min 35s\nWall time: 2h 11min 3s\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# base_vit_p16.save(\"base_vit_p16_epoch0010.keras\")\nbase_vit_p16.save_pretrained(\"./base_vit_p16_in1k\")\njoblib.dump(history_base_vit_p16.history, \"history_base_vit_p16_epoch0015.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T06:07:03.260440Z","iopub.execute_input":"2025-06-13T06:07:03.260633Z","iopub.status.idle":"2025-06-13T06:07:04.046739Z","shell.execute_reply.started":"2025-06-13T06:07:03.260619Z","shell.execute_reply":"2025-06-13T06:07:04.045922Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['history_base_vit_p16_epoch0015.joblib']"},"metadata":{}}],"execution_count":21}]}